{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "needed-requirement",
   "metadata": {},
   "source": [
    "# CS4487 - Group Project - Group 22 test part only\n",
    "\n",
    "Name List:  \n",
    "CHENG Ho Man 56208961, CHENG Hong Wai 56216309, CHONG Chun Yu 56225263"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8460780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch library installation\n",
    "# pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu117\n",
    "# pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed116c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standard PyTorch modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# import torchvision module to handle image manipulation\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee29f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3,6,4)            # 3@299*299 -> 6@296*296\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2) # 6@296*296 -> 6@148*148\n",
    "\n",
    "        self.conv2 = nn.Conv2d(6,12,5)           # 6@148*148 -> 12@144*144    \n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2) # 12@144*144 -> 12@72*72\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(12,24,5)          # 12@72*72 -> 24@68*68\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2) # 24@68*68 -> 24@34*34\n",
    "\n",
    "        self.fc1 = nn.Linear(24*34*34,24*34)\n",
    "        self.fc2 = nn.Linear(24*34,24)\n",
    "        self.fc3 = nn.Linear(24,2)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        t = self.pool1(F.relu(self.conv1(t)))\n",
    "        t = self.pool2(F.relu(self.conv2(t)))\n",
    "        t = self.pool3(F.relu(self.conv3(t)))\n",
    "        \n",
    "        t = torch.flatten(t,1)\n",
    "        \n",
    "        t = F.relu(self.fc1(t))\n",
    "        t = F.relu(self.fc2(t))\n",
    "        t = self.fc3(t)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30225a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use GPU\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-portland",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T06:39:17.585369Z",
     "start_time": "2022-12-01T06:39:17.534560Z"
    }
   },
   "outputs": [],
   "source": [
    "# testing for TA\n",
    "test_dir = \"./data/test\" # insert data path here\n",
    "\n",
    "# transforms \n",
    "normalize = transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],std=[0.2023, 0.1994, 0.2010]) \n",
    "data_transform = transforms.Compose([transforms.ToTensor(),normalize])\n",
    "\n",
    "test_data = datasets.ImageFolder(root=test_dir, \n",
    "                                  transform=data_transform, \n",
    "                                  target_transform=None)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=35, shuffle=True)\n",
    "\n",
    "model_test = Network()\n",
    "model_test.load_state_dict(torch.load('model_cnn_3layer_final.ckpt',map_location=torch.device('cpu')))\n",
    "\n",
    "model_test.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for img, labels in test_loader:\n",
    "\n",
    "        preds = model_test(img)\n",
    "        \n",
    "        predicted = torch.max(preds.data, 1)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).float().sum()           \n",
    "\n",
    "    print('Testing accuracy: {} %'.format(100 * correct / total))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "46ff490efd5b3d75b63a8f28fe302eed9848f232a61c418da4839030ecbfd1b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
